{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODE_DIR = '/home/shreyas/Documents/git/wheelai/'\n",
    "traindata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/sample_train/'\n",
    "validdata_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/valid/'\n",
    "results_path = '/media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model,  Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Lambda, Cropping2D, Activation\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(path, class_mode='categorical', gen=image.ImageDataGenerator(), \\\n",
    "                shuffle=False, target_size=(470, 640), batch_size=1):\n",
    "    return gen.flow_from_directory(path, class_mode=class_mode, batch_size=batch_size, \\\n",
    "                                   target_size=target_size, shuffle=shuffle)\n",
    "\n",
    "def get_steps(batches, batch_size):\n",
    "    steps = int(batches.samples/batch_size)\n",
    "    return (steps if batches.samples%batch_size==0 else (steps+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12954 images belonging to 3 classes.\n",
      "Found 3375 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_b = get_batches(traindata_path, batch_size=batch_size)\n",
    "valid_b = get_batches(validdata_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_steps = get_steps(train_b, batch_size)\n",
    "valid_steps = get_steps(valid_b, batch_size)\n",
    "num_class = train_b.num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_b.classes\n",
    "valid_labels = valid_b.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_valid = keras.utils.to_categorical(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12954,) (3375,) (12954, 3) (3375, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape, valid_labels.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_b = get_batches(traindata_path, class_mode=None, shuffle=False, batch_size=batch_size)\n",
    "val_b = get_batches(validdata_path, class_mode=None, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_augdata = image.ImageDataGenerator(width_shift_range=.2, height_shift_range=.2, \n",
    "                                      shear_range=0.2, zoom_range=0.2)\n",
    "augtrain_b = get_batches(traindata_path, gen=gen_augdata, class_mode='categorical',\\\n",
    "                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def resnet50():\n",
    "    model = ResNet50(include_top = False, weights='imagenet', input_shape=(200, 400, 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/255.-0.5,input_shape=input_shape))\n",
    "    model.add(Convolution2D(3,1,1,\n",
    "                        border_mode='valid',\n",
    "                        name='conv0', init='he_normal'))\n",
    "    model.add(Convolution2D(32,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv1', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv2', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv3', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Convolution2D(64,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv4', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(128,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv5', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(128,filter_size,filter_size,\n",
    "                        border_mode='valid',\n",
    "                        name='conv6', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,name='hidden1', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64,name='hidden2', init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16,name='hidden3',init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, name='output', init='he_normal'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ft(trn_b, train_steps, val_b, valid_steps):\n",
    "    model = vgg_conv()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    trn_ft = model.predict_generator(trn_b, train_steps)\n",
    "    val_ft = model.predict_generator(val_b, valid_steps)\n",
    "    print(trn_ft.shape, val_ft.shape)\n",
    "\n",
    "    np.save(results_path + 'trn_ft.npy', trn_ft)\n",
    "    np.save(results_path + 'val_ft.npy', val_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "get_ft(trn_b, train_steps, val_b, valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load(results_path + 'trn_ft.npy')\n",
    "X_valid = np.load(results_path + 'val_ft.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = top_layer(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=2e-5), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vgg_model.fit(X_train, y_train, epochs=2, batch_size=1, verbose=1, \\\n",
    "#          validation_data=(X_valid, y_valid))\n",
    "#vgg_model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=10,\\\n",
    "#                   validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(results_path+'trial_bottleneck.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath1 = results_path+'vgg_bottleneck.h5'\n",
    "checkpoint1 = ModelCheckpoint(filepath1, monitor='val_loss', verbose=1, save_best_only=False,\\\n",
    "                             save_weights_only=True, mode='min', period=1)\n",
    "callbacks1=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12954 samples, validate on 9687 samples\n",
      "Epoch 1/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.6293 - acc: 0.7323Epoch 00000: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 176s - loss: 0.6294 - acc: 0.7323 - val_loss: 0.8867 - val_acc: 0.7107\n",
      "Epoch 2/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.5678 - acc: 0.7567Epoch 00001: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 194s - loss: 0.5675 - acc: 0.7569 - val_loss: 1.0157 - val_acc: 0.6720\n",
      "Epoch 3/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.7693Epoch 00002: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 145s - loss: 0.5396 - acc: 0.7695 - val_loss: 1.0672 - val_acc: 0.6539\n",
      "Epoch 4/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.5176 - acc: 0.7774Epoch 00003: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 173s - loss: 0.5176 - acc: 0.7772 - val_loss: 1.2257 - val_acc: 0.5680\n",
      "Epoch 5/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.4926 - acc: 0.7896Epoch 00004: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 176s - loss: 0.4923 - acc: 0.7899 - val_loss: 1.1325 - val_acc: 0.6459\n",
      "Epoch 6/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.7989Epoch 00005: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 170s - loss: 0.4675 - acc: 0.7988 - val_loss: 1.2183 - val_acc: 0.5762\n",
      "Epoch 7/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8115Epoch 00006: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 177s - loss: 0.4451 - acc: 0.8117 - val_loss: 1.2565 - val_acc: 0.6016\n",
      "Epoch 8/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.4178 - acc: 0.8229Epoch 00007: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 193s - loss: 0.4178 - acc: 0.8228 - val_loss: 1.3694 - val_acc: 0.5519\n",
      "Epoch 9/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.3907 - acc: 0.8386Epoch 00008: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 179s - loss: 0.3908 - acc: 0.8385 - val_loss: 1.2882 - val_acc: 0.6104\n",
      "Epoch 10/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.3592 - acc: 0.8534Epoch 00009: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 190s - loss: 0.3592 - acc: 0.8535 - val_loss: 1.3197 - val_acc: 0.6115\n",
      "Epoch 11/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.8656Epoch 00010: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 178s - loss: 0.3297 - acc: 0.8655 - val_loss: 1.6110 - val_acc: 0.5036\n",
      "Epoch 12/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.8792Epoch 00011: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 174s - loss: 0.3001 - acc: 0.8792 - val_loss: 1.6013 - val_acc: 0.5101\n",
      "Epoch 13/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.8936Epoch 00012: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 190s - loss: 0.2693 - acc: 0.8935 - val_loss: 1.5012 - val_acc: 0.5542\n",
      "Epoch 14/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9075Epoch 00013: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 178s - loss: 0.2398 - acc: 0.9074 - val_loss: 1.8859 - val_acc: 0.4945\n",
      "Epoch 15/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9215Epoch 00014: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 169s - loss: 0.2097 - acc: 0.9216 - val_loss: 1.9304 - val_acc: 0.4894\n",
      "Epoch 16/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9319Epoch 00015: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 191s - loss: 0.1862 - acc: 0.9319 - val_loss: 2.2823 - val_acc: 0.4459\n",
      "Epoch 17/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9409Epoch 00016: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 194s - loss: 0.1635 - acc: 0.9409 - val_loss: 2.6379 - val_acc: 0.3871\n",
      "Epoch 18/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9469Epoch 00017: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 185s - loss: 0.1449 - acc: 0.9469 - val_loss: 2.7938 - val_acc: 0.3682\n",
      "Epoch 19/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9560Epoch 00018: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 189s - loss: 0.1246 - acc: 0.9559 - val_loss: 1.5839 - val_acc: 0.6539\n",
      "Epoch 20/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9626Epoch 00019: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 176s - loss: 0.1110 - acc: 0.9626 - val_loss: 2.7054 - val_acc: 0.4074\n",
      "Epoch 21/21\n",
      "12928/12954 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9660Epoch 00020: saving model to /media/shreyas/DATA/ML_DATA/wheelai/gtaV/results/vgg_bottleneck.h5\n",
      "12954/12954 [==============================] - 175s - loss: 0.1032 - acc: 0.9658 - val_loss: 3.0608 - val_acc: 0.4161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d092ef0b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=21, batch_size=32, verbose=1, \\\n",
    "          callbacks=callbacks1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_model():\n",
    "    base_model = vgg_conv()\n",
    "    for layer in base_model.layers[:11]: layer.trainable=False\n",
    "    print (base_model.output_shape[1:])\n",
    "    top_model = top_layer(base_model.output_shape[1:])\n",
    "    top_model.load_weights(results_path+'vgg_bottleneck.h5')\n",
    "    \n",
    "    base_model.add(top_model)\n",
    "    \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "vgg_model = vgg_model()\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=2e-5, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath2 = results_path+'vgg_ft.h5'\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1,\\\n",
    "                              save_best_only=False, mode='min', period=1)\n",
    "callbacks2=[checkpoint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "810/810 [==============================] - 1036s - loss: 0.1937 - acc: 0.9354 - val_loss: 1.5086 - val_acc: 0.5153\n",
      "Epoch 2/21\n",
      "810/810 [==============================] - 1063s - loss: 0.1676 - acc: 0.9485 - val_loss: 1.4468 - val_acc: 0.5206\n",
      "Epoch 3/21\n",
      "810/810 [==============================] - 503s - loss: 0.1507 - acc: 0.9552 - val_loss: 1.3934 - val_acc: 0.5265\n",
      "Epoch 4/21\n",
      "810/810 [==============================] - 576s - loss: 0.1369 - acc: 0.9593 - val_loss: 1.3802 - val_acc: 0.5289\n",
      "Epoch 5/21\n",
      "810/810 [==============================] - 632s - loss: 0.1257 - acc: 0.9654 - val_loss: 1.3798 - val_acc: 0.5301\n",
      "Epoch 6/21\n",
      "810/810 [==============================] - 530s - loss: 0.1173 - acc: 0.9684 - val_loss: 1.3748 - val_acc: 0.5256\n",
      "Epoch 7/21\n",
      "810/810 [==============================] - 532s - loss: 0.1108 - acc: 0.9695 - val_loss: 1.3925 - val_acc: 0.5194\n",
      "Epoch 8/21\n",
      "810/810 [==============================] - 554s - loss: 0.1040 - acc: 0.9722 - val_loss: 1.4026 - val_acc: 0.5227\n",
      "Epoch 9/21\n",
      "810/810 [==============================] - 601s - loss: 0.0971 - acc: 0.9765 - val_loss: 1.4008 - val_acc: 0.5239\n",
      "Epoch 10/21\n",
      "810/810 [==============================] - 703s - loss: 0.0931 - acc: 0.9768 - val_loss: 1.4014 - val_acc: 0.5262\n",
      "Epoch 11/21\n",
      "810/810 [==============================] - 632s - loss: 0.0862 - acc: 0.9812 - val_loss: 1.4429 - val_acc: 0.5250\n",
      "Epoch 12/21\n",
      "810/810 [==============================] - 1319s - loss: 0.0822 - acc: 0.9826 - val_loss: 1.4115 - val_acc: 0.5283\n",
      "Epoch 13/21\n",
      "809/810 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9835"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a09c20ed777a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m vgg_model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=21,\n\u001b[0;32m----> 2\u001b[0;31m                         validation_data=valid_b, validation_steps=valid_steps)\n\u001b[0m",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1897\u001b[0m                                 \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m                                 pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1900\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shreyas/anaconda3/envs/wheelai/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_q_size, workers, pickle_safe)\u001b[0m\n\u001b[1;32m   1977\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg_model.fit_generator(train_b, steps_per_epoch=train_steps, epochs=21,\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_path = results_path+'vgg_ft.json'\n",
    "model_json = model.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(filepath2)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath3 = results_path+'vgg_augmented_ft.h5'\n",
    "checkpoint3 = ModelCheckpoint(filepath3, monitor='val_loss', verbose=1,\\\n",
    "                              save_best_only=True, mode='min', period=1)\n",
    "callbacks3=[checkpoint3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_model.fit_generator(augtrain_b, steps_per_epoch=train_steps, epochs=13, callbacks=callbacks3,\\\n",
    "                        validation_data=valid_b, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(results_path+'vgg_ft_augmenteddata.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (preds[:5])\n",
    "img = batches.filenames\n",
    "print (img[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(DATA_DIR+'test/'+img[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(results_path + 'test_predictions.dat', preds)\n",
    "save_array(results_path + 'imagefiles.dat', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Predictions\n",
    "Lets plot -\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. Most confident correct predictions of each class\n",
    "4. Most confident incorrect predictions of each class\n",
    "5. Most uncertain labels (probabilites close to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(validdata_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = val_batches.filenames\n",
    "expected_labels = val_batches.classes\n",
    "\n",
    "our_predictions = probs[:,0]\n",
    "other_predictions = np.round(probs[:,1])\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(validdata_path + img[i]) for i in idx], titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print (\"Found %d correct labels\" % len(correct))\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print (\"Found %d confident correct cats labels\" % len(correct_cats))\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print (\"Found %d confident correct dogs labels\" % len(correct_dogs))\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print (\"Found %d incorrect cats\" % len(incorrect_cats))\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print (\"Found %d incorrect dogs\" % len(incorrect_dogs))\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array(results_path + 'test_predictions.dat')\n",
    "filenames = load_array(results_path + 'imagefiles.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isdog = preds[:,1]\n",
    "print (\"Raw Predictions: \"+ str(isdog[:5]))\n",
    "print (\"Mid Predictions: \"+str(isdog[(isdog<.6)&(isdog>0.4)]))\n",
    "print (\"Edge Predictions: \"+str(isdog[(isdog<0.02)&(isdog>.98)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.amax(isdog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_DIR\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
