{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(\n",
    "    32, \n",
    "    (3, 3),                               # subset of the picture; this is moved around the picture. As the\n",
    "    activation=\"relu\",                    # subset is 3x3, we have only 26 ways how it can be moved on an axis\n",
    "    input_shape=(28, 28, 1)               # the 1 stands for the color depth (grayscale = 1, RGB would be 3).\n",
    "))                                        # the convolution is a 'NN inside a NN' ()\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))    # takes the maximum for a given 3x3 picture\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))   # ...\n",
    "model.add(layers.MaxPooling2D((2, 2)))                    # ...\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (60000, 28, 28)\n",
      "Test: (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d610b5cef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 5\n",
      "After: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"Train:\", train_images.shape)\n",
    "print(\"Test:\", test_images.shape)\n",
    "\n",
    "for i in range(1):\n",
    "    plt.imshow(train_images[i], cmap=\"gray\")\n",
    "    plt.title(\"image \" + str(i) + \": \" + str(train_labels[i]))\n",
    "    plt.show()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255.0\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"Before:\", train_labels[0])\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "print(\"After:\", train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14528/60000 [======>.......................] - ETA: 23:50 - loss: 0.4825 - acc: 0.8468"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=5, \n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(1, len(history.history[\"acc\"]) + 1)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(r, history.history[\"acc\"], label=\"acc\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(r, history.history[\"loss\"], label=\"loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"\\nLoss / Accuracy Evaluation\")\n",
    "print(\"--------------------------\")\n",
    "print(\"Loss:     \" + str(round(test_loss,5)))\n",
    "print(\"Accuracy: \" + str(round(test_acc,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutions take very long; we can use transfer learning though where we just train the layers _after_ the convolution layers. These were already trained by e.g. Google and can detect things like edges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
